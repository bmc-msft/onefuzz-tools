#!/usr/bin/env python

import argparse
import sys
import subprocess
import tempfile
import os
import time
import uuid
from typing import Optional, Callable, Tuple, TypeVar

import requests
from github import Github


A = TypeVar("A")


def wait(func: Callable[[], Tuple[bool, str, A]], frequency: float = 1.0) -> A:
    """
    Wait until the provided func returns True

    Provides user feedback via a spinner if stdout is a TTY.
    """

    isatty = sys.stdout.isatty()
    frames = ["-", "\\", "|", "/"]
    waited = False
    last_message = None
    result = None

    try:
        while True:
            result = func()
            if result[0]:
                break
            message = result[1]

            if isatty:
                if last_message:
                    if last_message == message:
                        sys.stdout.write("\b" * (len(last_message) + 2))
                    else:
                        sys.stdout.write("\n")
                sys.stdout.write("%s %s" % (frames[0], message))
                sys.stdout.flush()
            elif last_message != message:
                print(message, flush=True)

            last_message = message
            waited = True
            time.sleep(frequency)
            frames.sort(key=frames[0].__eq__)
    finally:
        if waited and isatty:
            print(flush=True)

    return result[2]


class Downloader:
    def __init__(self):
        self.gh = Github(login_or_token=os.environ["GITHUB_ISSUE_TOKEN"])

    def update_pr(self, repo_name: str, pr: int) -> None:
        pr_obj = self.gh.get_repo(repo_name).get_pull(pr)
        if pr_obj.mergeable_state == "behind":
            print(f"pr:{pr} out of date.  Updating")
            pr_obj.update_branch()
            time.sleep(5)
        elif pr_obj.mergeable_state == "dirty":
            raise Exception(f"merge confict errors on pr:{pr}")

    def merge_pr(self, repo_name: str, pr: int) -> None:
        pr_obj = self.gh.get_repo(repo_name).get_pull(pr)
        if pr_obj.mergeable_state == "clean":
            print(f"merging pr:{pr}")
            pr_obj.merge(commit_message="", merge_method="squash")
        else:
            print(f"unable to merge pr:{pr}", pr_obj.mergeable_state)

    def get_artifact(
        self,
        repo_name: str,
        workflow: str,
        branch: Optional[str],
        pr: Optional[int],
        name: str,
        filename: str,
    ) -> None:
        print(f"getting {name}")

        if pr:
            self.update_pr(repo_name, pr)
            branch = self.gh.get_repo(repo_name).get_pull(pr).head.ref
        if not branch:
            raise Exception("missing branch")

        zip_file_url = self.get_artifact_url(repo_name, workflow, branch, name)

        (code, resp, _) = self.gh._Github__requester.requestBlob(
            "GET", zip_file_url, {}
        )
        if code != 302:
            raise Exception(f"unexpected response: {resp}")

        with open(filename, "wb") as handle:
            for chunk in requests.get(resp["location"], stream=True).iter_content(
                chunk_size=1024 * 16
            ):
                handle.write(chunk)

    def get_artifact_url(
        self, repo_name: str, workflow_name: str, branch: str, name: str
    ) -> str:
        repo = self.gh.get_repo(repo_name)
        workflow = repo.get_workflow(workflow_name)
        run = workflow.get_runs(branch=branch)[0]

        def check():
            run.update()
            return run.status == "completed", run.status, None

        wait(check, frequency=10.0)

        if run.conclusion != "success":
            raise Exception(f"bad conclusion: {run.conclusion}")

        response = requests.get(run.artifacts_url).json()
        for artifact in response["artifacts"]:
            if artifact["name"] == name:
                return artifact["archive_download_url"]
        raise Exception(f"no archive url for {branch} - {name}")


class Deployer:
    def __init__(self, *, pr: int, branch: str, instance: str, region: str):
        self.downloader = Downloader()
        self.pr = pr
        self.branch = branch
        self.instance = instance
        self.region = region

    def merge(self) -> None:
        if self.pr:
            self.downloader.merge_pr(self.branch, self.pr)

    def deploy(self, filename: str) -> None:
        print(f"deploying {filename} to {self.instance}")
        venv = "deploy-venv"
        commands = [
            ("extracting release-artifacts", f"unzip -qq {filename}"),
            ("extracting deployment", "unzip -qq onefuzz-deployment*.zip"),
            ("setup venv", f"python -mvenv {venv}"),
            ("installing wheel", f"./{venv}/bin/pip install -q wheel"),
            ("installing prereqs", f"./{venv}/bin/pip install -q -r requirements.txt"),
            (
                "running deployment",
                (
                    f"./{venv}/bin/python deploy.py {self.region} "
                    f"{self.instance} {self.instance} cicd"
                ),
            ),
        ]
        for (msg, cmd) in commands:
            print(msg)
            subprocess.check_call(cmd, shell=True)

    def test(self, filename: str) -> None:
        venv = "test-venv"
        test_dir = "integration-test-artifacts"
        script = "integration-test.py"
        endpoint = f"https://{self.instance}.azurewebsites.net"
        commands = [
            (
                "extracting integration-test-artifacts",
                f"unzip -qq {filename} -d {test_dir}",
            ),
            ("test venv", f"python -mvenv {venv}"),
            ("installing wheel", f"./{venv}/bin/pip install -q wheel"),
            ("installing sdk", f"./{venv}/bin/pip install -q sdk/*.whl"),
            ("install azure-cli-core", f"./{venv}/bin/pip install -q azure-cli-core"),
            (
                "running integration",
                (
                    f"./{venv}/bin/python {test_dir}/{script} test {test_dir} "
                    f"--region {self.region} --endpoint {endpoint}"
                ),
            ),
        ]
        for (msg, cmd) in commands:
            print(msg)
            subprocess.check_call(cmd, shell=True)

        app_id = (
            subprocess.check_output(
                f"az monitor app-insights component show -a {self.instance} -g {self.instance}"
                " --query appId --output tsv",
                shell=True,
            )
            .decode()
            .strip()
        )

        queries = [
            "exceptions | count",
            'union traces | where message startswith "request error" | count',
            'union traces | where message startswith "error running" | count',
        ]

        for query in queries:
            count = (
                subprocess.check_output(
                    f"az monitor app-insights query --app {app_id} --analytics-query "
                    f"'{query}'  --offset 1h --query tables[0].rows[0] --output tsv"
                )
                .decode()
                .strip()
            )

            if count != "0":
                raise Exception(f"exceptions raised during testing {count}")

    def cleanup(self, skip: bool) -> None:
        if skip:
            return

        subprocess.call(
            ["az", "group", "delete", "-n", self.instance, "--yes", "--no-wait"]
        )

    def run(self, *, merge_on_success=False) -> None:
        filename = "release-artifacts.zip"
        self.downloader.get_artifact(
            "microsoft/onefuzz",
            "ci.yml",
            self.branch,
            self.pr,
            "release-artifacts",
            filename,
        )
        self.deploy(filename)

        filename = "integration-test-artifacts.zip"
        self.downloader.get_artifact(
            "microsoft/onefuzz",
            "ci.yml",
            self.branch,
            self.pr,
            "integration-test-artifacts",
            filename,
        )
        self.test(filename)

        if merge_on_success:
            self.merge()


def main() -> None:
    default_instance = "pr-check-%s" % uuid.uuid4().hex
    parser = argparse.ArgumentParser()
    parser.add_argument("--instance", default=default_instance)
    group = parser.add_mutually_exclusive_group()
    group.add_argument("--branch")
    group.add_argument("--pr", type=int)

    parser.add_argument("--region", default="eastus2")
    parser.add_argument("--skip-cleanup", action="store_true")
    parser.add_argument("--skip-cleanup-on-failure", action="store_true")
    parser.add_argument("--merge-on-success", action="store_true")
    args = parser.parse_args()

    if not args.branch and not args.pr:
        raise Exception("--branch or --pr is required")

    d = Deployer(
        branch=args.branch, pr=args.pr, instance=args.instance, region=args.region
    )
    with tempfile.TemporaryDirectory() as directory:
        os.chdir(directory)
        print(f"running from within {directory}")

        try:
            d.run(merge_on_success=args.merge_on_success)
            d.cleanup(args.skip_cleanup)
            return
        finally:
            if not args.skip_cleanup_on_failure:
                d.cleanup(args.skip_cleanup)


if __name__ == "__main__":
    main()
